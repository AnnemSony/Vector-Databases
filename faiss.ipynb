{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fJMLq-rXjZv",
    "outputId": "dffd43a7-c941-4fe9-a49d-6cefe832a265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        concept(gold)  concept_id\n",
      "0  history of total lobectomy of lung     4005751\n",
      "1                  open heart surgery     4094240\n",
      "2               intestinal absorption     2721192\n",
      "3                          loperamide      991876\n",
      "4                              anemia      381839\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_excel(\"/content/sample data.xlsx\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "id": "W46SvXn6Xk3w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (4.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (2023.3.23)\n",
      "Requirement already satisfied: filelock in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from transformers) (1.26.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: fsspec in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/s_annem/anaconda3/envs/tf_gpu/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AHB-MfBCXyIj"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CXxZe9NYXk6t"
   },
   "outputs": [],
   "source": [
    "# model_name='clinicalbert-base'\n",
    "#model_name='emilyalsentzer/Bio_ClinicalBERT'\n",
    "model_name='NeuML/pubmedbert-base-embeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1SkdD20aXk9-"
   },
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(model_name)\n",
    "#tokenizer used to splt the given text into tokens\n",
    "model=BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "id": "L_8lKyi3XlAV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annem\\AppData\\Local\\Temp\\ipykernel_22852\\3162721891.py:5: DtypeWarning: Columns (0,5,6,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path, sep='\\t', quoting=3, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   concept_id                             concept_name\n",
      "0  concept_id                             concept_name\n",
      "1    45756805                     Pediatric Cardiology\n",
      "2    45756804                 Pediatric Anesthesiology\n",
      "3    45756803  Pathology-Anatomic / Pathology-Clinical\n",
      "4    45756802                    Pathology - Pediatric\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_file_path = \"CONCEPT.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_file_path, sep='\\t', quoting=3, header=None)\n",
    "df.columns = [\"concept_id\", \"concept_name\", \"domain_id\", \"vocabulary_id\", \"concept_class_id\", \"standard_concept\", \"concept_code\", \"valid_start_date\", \"valid_end_date\", \"invalid_reason\"]\n",
    "\n",
    "df_selected = df[['concept_id', 'concept_name']]\n",
    "\n",
    "print(df_selected.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for concept_name in df_selected['concept_name'][:50]:\n",
    "   \n",
    "    if isinstance(concept_name, str):\n",
    "        input_ids = tokenizer(concept_name, return_tensors='pt').input_ids\n",
    "\n",
    "        with torch.no_grad():\n",
    "            concept_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        embeddings.append(concept_embedding)\n",
    "    else:\n",
    "        print(f\"Skipping concept_name: {concept_name} as it is not a valid string.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Faiss index\n",
    "dimension = len(embedding_array[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_array)\n",
    "\n",
    "# Save the Faiss index\n",
    "faiss.write_index(index, \"vector_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embeddings = []\n",
    "concept_names = []\n",
    "\n",
    "for concept_name in df_selected['concept_name'][:10]:\n",
    "    if isinstance(concept_name, str):\n",
    "        input_ids = tokenizer(concept_name, return_tensors='pt').input_ids\n",
    "\n",
    "        with torch.no_grad():\n",
    "            concept_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        embeddings.append(concept_embedding)\n",
    "        concept_names.append(concept_name)\n",
    "    else:\n",
    "        print(f\"Skipping concept_name: {concept_name} as it is not a valid string.\")\n",
    "\n",
    "# Convert the embeddings list to a numpy array\n",
    "embedding_array = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "# Create the Faiss index\n",
    "dimension = len(embedding_array[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_array)\n",
    "\n",
    "# Save the Faiss index\n",
    "faiss.write_index(index, \"vector_index.index\")\n",
    "\n",
    "# Save the concept names for each index\n",
    "np.save(\"concept_names.npy\", np.array(concept_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import torch\n",
    "\n",
    "loaded_index = faiss.read_index(\"vector_index.index\")\n",
    "concept_names = np.load(\"concept_names.npy\", allow_pickle=True)\n",
    "\n",
    "new_entity_name = \"  Pediatric Cardiolosgy\"  # Pass the entity here\n",
    "new_entity_input_ids = tokenizer(new_entity_name, return_tensors='pt').input_ids  # Tokenize the new entity\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_entity_embedding = model(new_entity_input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()  # Obtain the embedding\n",
    "\n",
    "k = 1  # Retrieve top 1\n",
    "distance, concept_indices = loaded_index.search(new_entity_embedding.reshape(1, -1), k)\n",
    "\n",
    "# Retrieve and print the actual concept names using the mapped indices\n",
    "related_concepts = [concept_names[idx] for idx in concept_indices[0]]\n",
    "\n",
    "print(\"Related Concepts for New Entity:\", new_entity_name)\n",
    "for concept in related_concepts:\n",
    "    print(concept)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3019791/22715337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconcept_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_selected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concept_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2788\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_valid_text_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2849\u001b[0m                 \u001b[0;34m\"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m                 \u001b[0;34m\"or `List[List[str]]` (batch of pretokenized examples).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "embeddings = []\n",
    "for concept_name in df_selected['concept_name']:\n",
    "    input_ids = tokenizer(concept_name, return_tensors='pt').input_ids\n",
    "\n",
    "    with torch.no_grad():\n",
    "        concept_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "    embeddings.append(concept_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping concept_name: nan as it is not a valid string.\n",
      "Skipping concept_name: nan as it is not a valid string.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for concept_name in df_selected['concept_name']:\n",
    "   \n",
    "    if isinstance(concept_name, str):\n",
    "        input_ids = tokenizer(concept_name, return_tensors='pt').input_ids\n",
    "\n",
    "        with torch.no_grad():\n",
    "            concept_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        embeddings.append(concept_embedding)\n",
    "    else:\n",
    "        print(f\"Skipping concept_name: {concept_name} as it is not a valid string.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "La1ZVrlhzVXQ",
    "outputId": "a535680b-4fc7-4001-f485-1c2f3c1b188d"
   },
   "outputs": [],
   "source": [
    "pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import faiss\n",
    "# import numpy as np\n",
    "\n",
    "# # Assuming 'embeddings' contains the embeddings and 'concept_names' contains corresponding concept names\n",
    "# # If the concept names are available separately\n",
    "# concept_names = df_selected['concept_name'].tolist()  # Retrieve concept names from the DataFrame\n",
    "\n",
    "# dimension = len(embeddings[0])\n",
    "# index = faiss.IndexFlatL2(dimension)  # Use Euclidean distance for the index\n",
    "# embedding_array = np.array(embeddings, dtype=np.float32)\n",
    "# index.add(embedding_array)\n",
    "\n",
    "# # Create a mapping between indices and concept names\n",
    "# index_to_concept_map = {i: name for i, name in enumerate(concept_names)}\n",
    "\n",
    "# # Save the index and the mapping for retrieval phase\n",
    "# faiss.write_index(index, \"vector_index.index\")\n",
    "# np.save(\"index_to_concept_map.npy\", index_to_concept_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hBA7cM7A-Yui"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "dimension = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dimension)#used Euclidian distance\n",
    "embedding_array = np.array(embeddings, dtype=np.float32)\n",
    "index.add(embedding_array)\n",
    "faiss.write_index(index, \"vector_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMevgQy_9ZQQ",
    "outputId": "1aa7d739-dbf8-4694-f03a-81d51b674b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related Concepts for New Entity: lungs of lobes\n",
      "Pathology-Anatomic / Pathology-Clinical\n"
     ]
    }
   ],
   "source": [
    "loaded_index = faiss.read_index(\"vector_index.index\")\n",
    "new_entity_name = \"lungs of lobes\"#pass entity here\n",
    "new_entity_input_ids = tokenizer(new_entity_name, return_tensors='pt').input_ids #tokeni\n",
    "with torch.no_grad():\n",
    "    new_entity_embedding = model(new_entity_input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()#embedding\n",
    "\n",
    "k = 1 #top1retreiving\n",
    "distance, concept_indices = loaded_index.search(new_entity_embedding.reshape(1, -1), k)\n",
    "related_concepts = [df_selected.iloc[idx]['concept_name'] for idx in concept_indices[0]]\n",
    "\n",
    "print(\"Related Concepts for New Entity:\", new_entity_name)\n",
    "for concept in related_concepts:\n",
    "    print(concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "loaded_index = faiss.read_index(\"vector_index.index\")\n",
    "\n",
    "input_file = \"Usagi_eval.xlsx\"\n",
    "output_file = \"output_results.xlsx\"\n",
    "\n",
    "input_df = pd.read_excel(input_file)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in input_df.iterrows():\n",
    "    entity = row['Entity']\n",
    "    ground_truth = row['Concept(gold)']\n",
    "    \n",
    "    #  'entity' is a valid string\n",
    "    if isinstance(entity, str):\n",
    "        input_ids = tokenizer(entity, return_tensors='pt').input_ids\n",
    "        with torch.no_grad():\n",
    "            entity_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        k = 1  # Retrieve the top 1 concept\n",
    "        distance, concept_indices = loaded_index.search(entity_embedding.reshape(1, -1), k)\n",
    "\n",
    "        related_concept = df_selected.iloc[concept_indices[0][0]]['concept_name']\n",
    "\n",
    "        results.append([entity, ground_truth, related_concept])\n",
    "    else:\n",
    "        print(f\"Skipping entity: {entity} as it is not a valid string.\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Entity', 'GroundTruth', 'RelatedConcept'])\n",
    "\n",
    "results_df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import faiss\n",
    "\n",
    "loaded_index = faiss.read_index(\"vector_index.index\")\n",
    "\n",
    "input_file = \"Usagi_eval.xlsx\"\n",
    "output_file = \"output_results.xlsx\"\n",
    "\n",
    "input_df = pd.read_excel(input_file)\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for index, row in input_df.head(20).iterrows():\n",
    "    entity = row['Entity']\n",
    "    ground_truth = row['Concept(gold)']\n",
    "    \n",
    "   \n",
    "    if isinstance(entity, str):\n",
    "        input_ids = tokenizer(entity, return_tensors='pt').input_ids\n",
    "        with torch.no_grad():\n",
    "            entity_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        k = 1  \n",
    "        distance, concept_indices = loaded_index.search(entity_embedding.reshape(1, -1), k)\n",
    "\n",
    "        related_concept = df_selected.iloc[concept_indices[0][0]]['concept_name']\n",
    "\n",
    "        results.append([entity, ground_truth, related_concept])\n",
    "    else:\n",
    "        print(f\"Skipping entity: {entity} as it is not a valid string.\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Entity', 'GroundTruth', 'RelatedConcept'])\n",
    "\n",
    "results_df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "output_file = \"output_results.xlsx\"\n",
    "results_df = pd.read_excel(output_file)\n",
    "\n",
    "ground_truth = results_df['GroundTruth']\n",
    "predicted_concepts = results_df['RelatedConcept']\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(ground_truth, predicted_concepts)\n",
    "\n",
    "precision = precision_score(ground_truth, predicted_concepts, average='micro')\n",
    "recall = recall_score(ground_truth, predicted_concepts, average='micro')\n",
    "f1 = f1_score(ground_truth, predicted_concepts, average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LHvzNnqE99K"
   },
   "outputs": [],
   "source": [
    "# mean averages\n",
    "#.squeeze() removes any redundant dimensions,\n",
    "#converting the tensor into a one-dimensional tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rzCWlSzoXlI_"
   },
   "outputs": [],
   "source": [
    "# embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "zgr0wYFzzVUI"
   },
   "outputs": [],
   "source": [
    "# import faiss\n",
    "# index = faiss.IndexFlatL2(embeddings[0].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TNldqB08zVdZ"
   },
   "outputs": [],
   "source": [
    "# embedding_array = np.array(embeddings, dtype=np.float32)\n",
    "# index.add(embedding_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPpzcEqC7Yye",
    "outputId": "87040f1e-e400-494d-aebd-cbe088e5d8ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11773689,  0.16933465,  0.28359666, ...,  0.6540919 ,\n",
       "        -0.29623917,  0.37046832],\n",
       "       [-0.61652166,  0.27194324, -0.85910165, ..., -0.21059635,\n",
       "         0.66623867, -0.02411818],\n",
       "       [-1.2852491 , -0.2501228 , -0.4878367 , ..., -0.0978955 ,\n",
       "        -0.52875453, -0.18915473],\n",
       "       ...,\n",
       "       [-0.63698983, -0.04616853, -0.5410171 , ...,  0.13265307,\n",
       "        -0.23601161, -0.8517514 ],\n",
       "       [-1.2534174 ,  1.1010355 ,  0.32653096, ..., -0.40512815,\n",
       "         0.17378646,  0.30994403],\n",
       "       [-0.35723314, -0.4312334 , -0.6614497 , ..., -0.04284064,\n",
       "        -0.33909023, -0.07046733]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vP1OvJPe9ZGr",
    "outputId": "f554a3b8-d2da-4d64-a6c5-a4a9fdfecde1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related Concepts for New Entity: lobes of the lung\n",
      "history of total lobectomy of lung\n"
     ]
    }
   ],
   "source": [
    "# new_entity_name = \"lobes of the lung\"\n",
    "# new_entity_input_ids = tokenizer(new_entity_name, return_tensors='pt').input_ids\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     new_entity_embedding = model(new_entity_input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# k = 1\n",
    "# distance, concept_indices = index.search(new_entity_embedding.reshape(1, -1), k)\n",
    "\n",
    "# related_concepts = [df.iloc[idx]['concept(gold)'] for idx in concept_indices[0]]\n",
    "\n",
    "# print(\"Related Concepts for New Entity:\", new_entity_name)\n",
    "# for concept in related_concepts:\n",
    "#     print(concept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7VigWDv9ZMk"
   },
   "outputs": [],
   "source": [
    "# stores in local database\n",
    "#faiss.write_index(index, \"vector_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMlBb0AhN5x5",
    "outputId": "dfb72d9d-95fc-416c-aef6-7f4fa336516d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 16 14 12  1 15 13  5  3  4]]\n"
     ]
    }
   ],
   "source": [
    "print(concept_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qbarmMRDYwM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pmH8Lk-MDYy-",
    "outputId": "72cd7956-69e6-4b2c-9073-471ed8606096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "loaded_index = faiss.read_index(\"vector_index.index\")\n",
    "num_vectors = loaded_index.ntotal\n",
    "print(num_vectors)\n",
    "num_to_print = min(num_vectors, 10)\n",
    "\n",
    "for i in range(num_to_print):\n",
    "    vector = loaded_index.reconstruct(i)\n",
    "    #print(f\"Vector {i}:\", vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs65-6qoDY1u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-S8cnNx8OlNo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annem\\AppData\\Local\\Temp\\ipykernel_22852\\1339461616.py:9: DtypeWarning: Columns (0,5,6,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path, sep='\\t', quoting=3, header=None)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load CSV file into a pandas DataFrame\n",
    "csv_file_path = \"CONCEPT.csv\"\n",
    "df = pd.read_csv(csv_file_path, sep='\\t', quoting=3, header=None)\n",
    "df.columns = [\"concept_id\", \"concept_name\", \"domain_id\", \"vocabulary_id\", \"concept_class_id\", \"standard_concept\", \"concept_code\", \"valid_start_date\", \"valid_end_date\", \"invalid_reason\"]\n",
    "\n",
    "df_selected = df[['concept_id', 'concept_name']]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "\n",
    "embeddings = []\n",
    "concept_names = []\n",
    "for concept_name in df_selected['concept_name'][:10]:\n",
    "    if isinstance(concept_name, str):\n",
    "       \n",
    "        input_ids = tokenizer(concept_name, return_tensors='pt').input_ids\n",
    "\n",
    "        with torch.no_grad():\n",
    "            concept_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        embeddings.append(concept_embedding)\n",
    "        concept_names.append(concept_name)\n",
    "    else:\n",
    "        print(f\"Skipping concept_name: {concept_name} as it is not a valid string.\")\n",
    "embedding_array = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "dimension = len(embedding_array[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_array)\n",
    "\n",
    "\n",
    "faiss.write_index(index, \"vector_index.index\")\n",
    "\n",
    "np.save(\"concept_names.npy\", np.array(concept_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zd6dqaUHOlYC"
   },
   "outputs": [],
   "source": [
    "# Prepare lists to store embeddings and concept names\n",
    "embeddings = []\n",
    "concept_names = []\n",
    "\n",
    "# Process all concepts\n",
    "total_concepts = len(df_selected)\n",
    "for i, concept_name in enumerate(df_selected['concept_name']):\n",
    "    if isinstance(concept_name, str):\n",
    "        # Tokenize and obtain embeddings\n",
    "        input_ids = tokenizer(concept_name, return_tensors='pt').input_ids\n",
    "\n",
    "        with torch.no_grad():\n",
    "            concept_embedding = model(input_ids)['last_hidden_state'].mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        embeddings.append(concept_embedding)\n",
    "        concept_names.append(concept_name)\n",
    "\n",
    "        # Display progress\n",
    "        print(f\"Processed concept {i + 1}/{total_concepts}: {concept_name}\")\n",
    "    else:\n",
    "        print(f\"Skipping concept_name: {concept_name} as it is not a valid string.\")\n",
    "\n",
    "# Convert the embeddings list to a numpy array\n",
    "embedding_array = np.array(embeddings, dtype=np.float32)\n",
    "\n",
    "# Create the Faiss index\n",
    "dimension = len(embedding_array[0])\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_array)\n",
    "\n",
    "# Save the Faiss index\n",
    "faiss.write_index(index, \"vector_index.index\")\n",
    "\n",
    "# Save the concept names for each index\n",
    "np.save(\"concept_names.npy\", np.array(concept_names))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
